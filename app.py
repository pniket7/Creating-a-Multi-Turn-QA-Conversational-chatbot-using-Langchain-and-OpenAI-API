# -*- coding: utf-8 -*-
"""QA Chatbot Using Langchain.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sSh20w-EH2vU2k-HQ2t1n9fKxphSAPYW
"""

#!pip install openai

#!pip install langchain

#!pip install pypdf

#!pip install chromadb

#!pip install tiktoken

# Import libraries
import os
import time
import tempfile
from langchain.chains import RetrievalQA
from langchain.llms import OpenAI
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.memory import SimpleMemory

# Set up OpenAI API credentials
os.environ["OPENAI_API_KEY"] = "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"

# Import the pdf document used for training
pdf_file_path='DP1Merrill_Manual_en.pdf'

# Load document
loader = PyPDFLoader(pdf_file_path)
documents = loader.load()

# Define the number of relevant chunks (k)
k = 2

# Define the chain type
chain_type = 'map_reduce'

# Split the documents into chunks
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
texts = text_splitter.split_documents(documents)

# Select which embeddings we want to use
embeddings = OpenAIEmbeddings()

# Create the vector store to use as the index
db = Chroma.from_documents(texts, embeddings)

# Expose this index in a retriever interface
retriever = db.as_retriever(search_type="similarity", search_kwargs={"k": k})

# Create a chain to answer questions
qa_chain = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=chain_type, retriever=retriever, return_source_documents=True)

# Define the conversation history list
conversation_history = []

def run_conversation(query):

    # Add the query and context to the conversation history
    conversation_history.append(query)

    # Prepare the conversation and get results
    result = qa_chain({"query": query, "context": conversation_history})

    # Store the conversation item
    conversation_history.append(result['result'])

    # Print the bot's response
    print("Bot:", result['result'])

# Start the conversation loop
print("Bot: Hello! I'm your conversation bot. Ask me anything or type 'exit' to end.")

while True:
    user_input = input("You: ")  # Get user input

    if user_input.lower() == 'exit':
        print("Bot: Goodbye!")
        break

    # Provide the user input to the conversation and get the bot's response
    run_conversation(user_input)

    print("")

